{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iyWC-HByOXFT"
   },
   "source": [
    "# Milestone 3: Alzheimer's Group 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yw-IQgSgOXFV"
   },
   "source": [
    "#### Daniel Graziano, Daniel Molina Hurtado, Esmail Fadae, Paxton Maeder-York"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovJUb3gUOXFW"
   },
   "source": [
    "Our strategy is to look at all the supporting datasets, pull out columns that are relevant and join based on patient ID (RID), only saving test rows that occured post diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdSQNMQpQGSC"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, we are going to work with the vast amount of information provided by the Alzheimerâ€™s Disease Neuroimaging Initiative (ADNI). This data has been colected by researchers at more than 60 sites in the US and Canada working with thousands of participants between the ages of 55 and 90. Participants can start the study with normal cognitive function, mild cognitive impairment (MCI) or Alzheimer's Desease (AD). The project is divided in several phases in time: ADNI1 (2004-2009), ADNIGO(2009-2001), ADNI2(2011-2016) and ADNI3(2016-2021). The study collects different types of data such as demographics, family history, genetics, neuropsycologichal tests, imaging or biomarkers.\n",
    "\n",
    "Our initial goal in this project will be to determine the most effective biomarkers and neuropsychological tests in order to predict Alzheimer's disease. If time permits we will also focus on summary imaging data but that is out of scope for now. \n",
    "\n",
    "We will start by exploring and putting together data from different datasets in different areas, cleaning it and preparing it for modeling and making predictions in further stages of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nfFXktcSOXFX"
   },
   "source": [
    "#### Libraries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wqbonxuoI5o"
   },
   "outputs": [],
   "source": [
    "#Basic Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import requests\n",
    "\n",
    "#Preprocessing Imports\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing.imputation import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Model Imports\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Plotting Imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "#Other Imports\n",
    "from scipy.special import gamma\n",
    "from IPython.display import display\n",
    "from typing import List, Tuple, Dict\n",
    "from io import BytesIO\n",
    "\n",
    "#Keras Imports\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Flatten, Dropout, UpSampling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxgugjixoVEU"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Import some data from our shared google drive folder\n",
    "\n",
    "#file_id comes from the end of the shareable link of the file from google drive\n",
    "#it is a set of alphanumeric characters after the '/d/ tag in the share URL\n",
    "#or the 'id' label, see example below\n",
    "#https://drive.google.com/open?id=1FSjJjpS1Ob_BEbshyl9dXb1FFmCnZrHE\n",
    "#have to decode the bytes before it can be read by pandas into df\n",
    "\n",
    "def read_gdrive_data(file_id):\n",
    "  response = requests.get('https://drive.google.com/uc?export=download&id=%s' % file_id)\n",
    "  df = pd.read_csv(BytesIO(response.content),na_values='-4')\n",
    "  return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
